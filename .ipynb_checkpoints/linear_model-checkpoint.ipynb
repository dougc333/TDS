{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook adapted from Jeremy P. Howard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random, randn\n",
    "from matplotlib import pyplot as plt, animation, rcParams, rc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function(alpha,beta,x): return alpha+beta*x\n",
    "rc('animation',html='html5')\n",
    "rcParams['figure.figsize'] = 3, 3\n",
    "\n",
    "beta_true = 6.0\n",
    "alpha_true = 3.0\n",
    "n = 30\n",
    "x = random(n)\n",
    "y = linear_function(alpha_true,beta_true,x)+0.2*randn(n)\n",
    "beta = -1.\n",
    "alpha = 3.\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Square error is square of difference between predicted and actual data values</p>\n",
    "Define predicted: ${\\hat y} $ and actual:${y}$ \n",
    "<p>Loss is:</p>\n",
    "$({\\hat y}-{y})^2$\n",
    "<p>Previous definition y as linear_function</p>\n",
    "${\\hat y=\\alpha + \\beta x}$\n",
    "<p>To minmize the Loss we take the derivative of the loss wrt alpha and beta, not x. x and y are datapoints\n",
    "which is our dataset we are trying to fit to. The derivative of y is the sum of the partial derivatives of the dependent variables\n",
    "which in this case are alpha and beta. </p>\n",
    "<p></p>\n",
    "$derivative(loss)=\\cfrac{\\partial(loss)}{\\partial \\alpha} + \\cfrac{\\partial(loss)}{\\partial \\beta}$\n",
    "<p></p>\n",
    "$\\cfrac{\\partial(loss)}{\\partial \\alpha}=\\cfrac{(\\hat y - y)^2}{\\partial \\alpha}=\\cfrac{2*(\\hat y-y)*\\partial(\\hat y - y)}{\\partial \\alpha}$\n",
    "<p>Using:</p>\n",
    "$\\cfrac{\\partial \\hat y}{\\partial \\alpha}=1$ \n",
    "<p>and</p>\n",
    "$\\cfrac{\\partial y}{\\partial \\alpha}=0$\n",
    "<p>the derivative of loss wrt alpha for y-hat is:</p>\n",
    "$\\cfrac{\\partial (loss)}{\\partial \\alpha}=2(\\hat y-y)$\n",
    "<p>The derivative of loss WRT beta starts as:</p>  \n",
    "$\\cfrac{\\partial(loss)}{\\partial \\beta}=\\cfrac{(\\hat y - y)^2}{\\partial \\beta}=\\cfrac{2*(\\hat y-y)}{\\partial \\beta}*\\cfrac{\\partial(\\hat y -y)}{\\partial \\beta}$\n",
    "<p></p>\n",
    "$\\cfrac{\\partial \\hat y}{\\partial \\beta}=x$ and\n",
    "$\\cfrac{\\partial y}{\\partial \\beta}=0$\n",
    "<p>the derivative of loss wrt beta for y-hat is:</p>\n",
    "$\\cfrac{\\partial (loss)}{\\partial \\beta}=2x*(\\hat y-y)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha_and_beta():\n",
    "    global alpha, beta\n",
    "    y_predicted = linear_function(alpha,beta,x)\n",
    "    derivative_of_loss_wrt_alpha = 2*(y_predicted-y)\n",
    "    derivative_of_loss_wrt_beta = x* derivative_of_loss_wrt_alpha\n",
    "    alpha = alpha - learning_rate*derivative_of_loss_wrt_alpha.mean()\n",
    "    beta = beta - learning_rate*derivative_of_loss_wrt_beta.mean()\n",
    "# i is the frame nuber!\n",
    "#https://math.unice.fr/~hheumann/Tutorial/_build/intro_matplotlib.html\n",
    "def animate(i):\n",
    "    x = np.linspace(0,1,100)\n",
    "    y = linear_function(alpha,beta,x)\n",
    "    line.set_data(x,y)\n",
    "    for i in range(20): \n",
    "        update_alpha_and_beta()\n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=80,figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((-2,15))\n",
    "plt.scatter(x,y)\n",
    "line, = ax.plot([],[],lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation = animation.FuncAnimation(fig,animate,frames=np.arange(0,250),interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out (or delete) the following command, which shows the animation in Jupyter Notebook, \n",
    "# if you want the mp4 saved to disk to be correctly animated. \n",
    "# (Alternatively, you can reset the values of alpha and beta to their initial values \n",
    "# after this command.)\n",
    "\n",
    "resulting_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "resulting_animation.save('linear_animation.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done linear animation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y=\\gamma x^2 + \\beta x + \\alpha$\n",
    "<p></p>\n",
    "$\\cfrac{\\partial(loss)}{\\partial \\gamma}=2x^2(\\hat y-y)$\n",
    "$\\cfrac{\\partial(loss)}{\\partial \\beta}=2x(\\hat y -y)$\n",
    "$\\cfrac{\\partial(loss)}{\\partial \\alpha}=2(\\hat y-y)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Squared Function</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It doesnt make sense to use a quadratic to approximate a linear function,so change the dataset to \n",
    "#be quadratic\n",
    "def square_function(gamma, beta, alpha,x):\n",
    "    return gamma*x**2 + beta*x + alpha\n",
    "\n",
    "beta_true = 2.0\n",
    "alpha_true = 2.0\n",
    "gamma_true = 10.0\n",
    "\n",
    "n = 300\n",
    "x = random(n)\n",
    "y = square_function(gamma_true,beta_true,alpha_true,x)+0.2*randn(n)\n",
    "beta = -1.\n",
    "alpha = 3.\n",
    "gamma = 2.\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_squared():\n",
    "    global gamma, alpha, beta\n",
    "    y_predicted = square_function(gamma,beta,alpha,x)\n",
    "    derivative_of_loss_wrt_gamma = 2*x**2*(y_predicted-y)\n",
    "    derivative_of_loss_wrt_alpha = 2*(y_predicted-y)\n",
    "    derivative_of_loss_wrt_beta = x* derivative_of_loss_wrt_alpha\n",
    "    alpha = alpha - learning_rate*derivative_of_loss_wrt_alpha.mean()\n",
    "    beta = beta - learning_rate*derivative_of_loss_wrt_beta.mean()\n",
    "    gamma = gamma - learning_rate * derivative_of_loss_wrt_gamma.mean()\n",
    "\n",
    "def animate(i):\n",
    "    x = np.linspace(0,1,100)\n",
    "    y = square_function(gamma,beta,alpha,x)\n",
    "    line.set_data(x,y)\n",
    "    for i in range(20): \n",
    "        update_squared()\n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=80,figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((-2,15))\n",
    "plt.scatter(x,y)\n",
    "line, = ax.plot([],[],lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation = animation.FuncAnimation(fig,animate,np.arange(0,250),interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "resulting_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=30, metadata=dict(artist='Me'), bitrate=1800)\n",
    "resulting_animation.save('squared_animation.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done squared animation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>SGD</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should be slower than gradient descent. \n",
    "import numpy as np\n",
    "from numpy.random import random, randn\n",
    "from matplotlib import pyplot as plt, animation, rcParams, rc\n",
    "\n",
    "\n",
    "def linear_function(alpha,beta,x): \n",
    "    return alpha+beta*x\n",
    "\n",
    "#constants\n",
    "beta_true = 6.0\n",
    "alpha_true = 3.0\n",
    "n = 30\n",
    "x = random(n)\n",
    "y = linear_function(alpha_true,beta_true,x_data)+0.2*randn(n)\n",
    "beta = -1.\n",
    "alpha = 3.\n",
    "learning_rate = 0.1\n",
    "num_iters=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD requires a batch size of 1 \n",
    "def update_alpha_and_beta():\n",
    "    global alpha, beta\n",
    "    for i in range(n):\n",
    "        print(\"i:\",i)\n",
    "        y_predicted_batch = linear_function(alpha,beta,x_data[i])\n",
    "        derivative_of_loss_wrt_alpha = 2*(y_predicted_batch-y_data[i])\n",
    "        derivative_of_loss_wrt_beta = x_data[i]* derivative_of_loss_wrt_alpha\n",
    "        print(\"before iters\",\"alpha:\",alpha,\"beta:\",beta)\n",
    "        for _ in range(num_iters):\n",
    "            #print(\"y_predicted_batch:\",y_predicted_batch)\n",
    "            #print(\"x_batch:\",x_batch,\"y_batch:\",y_batch)\n",
    "            #print(\"learning_rate:\",learning_rate)\n",
    "            #print(\"2*learning_rate*(y_predicted_batch-y_batch)\",2*learning_rate*(y_predicted_batch-y_batch))\n",
    "            #print(\"2*x_batch*(y_predicted_batch-y_batch)\",2*x_batch*(y_predicted_batch-y_batch))\n",
    "            alpha = alpha - 2*learning_rate*(y_predicted_batch-y_data[i])\n",
    "            beta = beta - learning_rate*2*x_data[i]*(y_predicted_batch-y_data[i])\n",
    "            y_predicted_batch = linear_function(alpha,beta,x_data[i])\n",
    "        #print(\"after iters\",\"alpha:\",alpha,\"beta:\",beta)\n",
    "def animate(i):\n",
    "    x = np.linspace(0,1,100)\n",
    "    y = linear_function(alpha,beta,x)\n",
    "    line.set_data(x,y)\n",
    "    for _ in range(20):\n",
    "        update_alpha_and_beta()\n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=80,figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((-2,15))\n",
    "plt.scatter(x,y)\n",
    "line, = ax.plot([],[],lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation = animation.FuncAnimation(fig,animate,np.arange(0,250),interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bug here if it doesnt complete\n",
    "resulting_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "resulting_animation.save('SGD_animation.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>GD w/momentum</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random, randn\n",
    "from matplotlib import pyplot as plt, animation, rcParams, rc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function(alpha,beta,x): return alpha+beta*x\n",
    "rc('animation',html='html5')\n",
    "rcParams['figure.figsize'] = 3, 3\n",
    "\n",
    "beta_true = 6.0\n",
    "alpha_true = 3.0\n",
    "n = 30\n",
    "x = random(n)\n",
    "y = linear_function(alpha_true,beta_true,x)+0.2*randn(n)\n",
    "beta = -1.\n",
    "alpha = 3.\n",
    "learning_rate = 0.01\n",
    "initial_velocity=0.1\n",
    "\n",
    "mom=0.9\n",
    "v_alpha = 0\n",
    "v_beta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha_and_beta():\n",
    "    global alpha, beta,v_alpha,v_beta\n",
    "    #more efficient code w/o the loop bc it is vectorized\n",
    "    y_predicted = linear_function(alpha,beta,x)\n",
    "    derivative_of_loss_wrt_alpha = 2*(y_predicted-y)\n",
    "    derivative_of_loss_wrt_beta = x * derivative_of_loss_wrt_alpha\n",
    "    v_alpha = mom*v_alpha - np.mean(learning_rate*derivative_of_loss_wrt_alpha)\n",
    "    v_beta = mom*v_beta - np.mean(learning_rate*derivative_of_loss_wrt_beta)\n",
    "    alpha = alpha + v_alpha\n",
    "    beta = beta + v_beta\n",
    "    \n",
    "def animate(i):\n",
    "    x = np.linspace(0,1,100)\n",
    "    y = linear_function(alpha,beta,x)\n",
    "    line.set_data(x,y)\n",
    "    for i in range(20): \n",
    "        update_alpha_and_beta()\n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=80,figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((-2,15))\n",
    "plt.scatter(x,y)\n",
    "line, = ax.plot([],[],lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation = animation.FuncAnimation(fig,animate,np.arange(0,250),interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "resulting_animation.save('GD_w_mom_animation.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Test Vectorized mean</h6>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonvectorized version. do not do this. \n",
    "def update_alpha_and_beta():\n",
    "    global alpha, beta,v_alpha,v_beta\n",
    "    #more efficient code w/o the loop bc it is vectorized\n",
    "    for i in range(n):\n",
    "        y_predicted = linear_function(alpha,beta,x[i])\n",
    "        derivative_of_loss_wrt_alpha = 2*(y_predicted-y[i])\n",
    "        derivative_of_loss_wrt_beta = x[i] * derivative_of_loss_wrt_alpha\n",
    "        v_alpha = mom*v_alpha - (1/n)*learning_rate*derivative_of_loss_wrt_alpha\n",
    "        v_beta = mom*v_beta - (1/n)*learning_rate*derivative_of_loss_wrt_beta \n",
    "    alpha = alpha + v_alpha\n",
    "    beta = beta + v_beta\n",
    "    \n",
    "def animate(i):\n",
    "    x = np.linspace(0,1,100)\n",
    "    y = linear_function(alpha,beta,x)\n",
    "    line.set_data(x,y)\n",
    "    for i in range(20): \n",
    "        update_alpha_and_beta()\n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the code I see on blogs are wrong. Only JH got it right. \n",
    "import time\n",
    "test = np.random.rand(100000000)\n",
    "\n",
    "def vec_mean():\n",
    "    start_time = time.time()\n",
    "    test.mean()\n",
    "    end_time = time.time()\n",
    "    print(\"vec mean time:\",end_time-start_time)\n",
    "def nonvec_mean():\n",
    "    start_time = time.time()\n",
    "    sum=0.\n",
    "    for i in range(len(test)):\n",
    "        sum += test[i]\n",
    "    mean = sum/len(test)\n",
    "    end_time = time.time()\n",
    "    print(\"nonvec mean time:\",end_time-start_time)\n",
    "    \n",
    "vec_mean()\n",
    "nonvec_mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Gradient Descent with Nesterov</h6>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The Loss function replaces theta with theta_tilde </p>\n",
    "$L(f(x^{(i)}); \\tilde \\theta,y^{(i)})$\n",
    "<p>where theta_tilde is theta with a constant times velocity</p>\n",
    "$\\tilde \\theta = \\theta + \\alpha v $\n",
    "<p>To calculate the gradient g we need to compute the partial derivatives of the loss function</p>\n",
    "$loss=(\\hat y -\\tilde y)$\n",
    "<p>where we convert theta to theta_tilde by replacing all the parameters in the linear equation with tilde versions</p>\n",
    "$y(\\tilde \\theta) = \\tilde A x + \\tilde B$ compared to before $y(\\theta) = Ax+b$\n",
    "<p>We changed notation from the earlier convention to avoid confusion with the IG defition of alpha as the\n",
    "momentum coefficient vs. alpha defined as a theta parameter as before</p>\n",
    "$Loss(\\tilde \\theta)=(\\hat y -y(\\tilde \\theta))^2$\n",
    "<p>Taking the partial derivatives of the loss WRT A and B which is the equivalent of taking the partials WRT alpha and beta earlier</p>\n",
    "$\\cfrac{\\partial Loss(\\tilde \\theta)}{\\partial A }=2(\\hat y -y(\\tilde \\theta)) \\cfrac{\\partial (\\tilde y - y(\\tilde \\theta))}{\\partial A}=2(\\hat y -y(\\tilde \\theta))(-x) $\n",
    "<p></p>\n",
    "$\\cfrac{\\partial Loss(\\tilde \\theta)}{\\partial B }= 2(\\hat y -y(\\tilde \\theta)) \\cfrac{\\partial (\\tilde y - y(\\tilde \\theta))}{\\partial B}=2(\\hat y -y(\\tilde \\theta))(-1) $\n",
    "<p>Converting the expectations to mean</p>\n",
    "$\\cfrac{\\partial Loss(\\tilde \\theta)}{\\partial A} = \\cfrac{-2}{N}\\sum_{1}^{N}x(\\hat y - y(\\theta))=\\cfrac{2}{N}\\sum_{1}^{N}x(y(\\theta)-\\hat y)$\n",
    "<p></p>\n",
    "$\\cfrac{\\partial Loss(\\tilde \\theta)}{\\partial B }= \\cfrac{-2}{N}\\sum_{1}^{N}(\\hat y - y(\\theta))=\\cfrac{2}{N}\\sum_{1}^{N}(y(\\theta)-\\hat y)$\n",
    "<p></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random, randn\n",
    "from matplotlib import pyplot as plt, animation, rcParams, rc\n",
    "\n",
    "def linear_function(alpha,beta,x): \n",
    "    return alpha+beta*x\n",
    "rc('animation',html='html5')\n",
    "rcParams['figure.figsize'] = 3, 3\n",
    "\n",
    "beta_true = 6.0\n",
    "alpha_true = 3.0\n",
    "n = 30\n",
    "x = random(n)\n",
    "y = linear_function(alpha_true,beta_true,x)+0.2*randn(n)\n",
    "beta = -1.\n",
    "alpha = 3.\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "mom=0.9\n",
    "v_alpha = 0\n",
    "v_beta = 0\n",
    "alpha_tilde=0\n",
    "beta_tilde=0\n",
    "loss = []\n",
    "num_times=0\n",
    "loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha_and_beta():\n",
    "    global alpha, beta,v_alpha,v_beta\n",
    "    #interim update\n",
    "    alpha_tilde = alpha + mom*v_alpha\n",
    "    beta_tilde = beta + mom*v_beta\n",
    "    \n",
    "    y_predicted = linear_function(alpha_tilde,beta_tilde,x)\n",
    "    derivative_of_loss_wrt_alpha_theta_tilde = 2*(y_predicted-y)\n",
    "    derivative_of_loss_wrt_beta_theta_tilde = x * derivative_of_loss_wrt_alpha_theta_tilde\n",
    "    #gradient update\n",
    "    v_alpha = mom*v_alpha - learning_rate*derivative_of_loss_wrt_alpha_theta_tilde.mean()\n",
    "    v_beta = mom*v_beta - learning_rate*derivative_of_loss_wrt_beta_theta_tilde.mean()\n",
    "    #velocity update\n",
    "    alpha = alpha + v_alpha\n",
    "    beta = beta + v_beta\n",
    "    l = (linear_function(alpha,beta,x)-y)**2\n",
    "    loss.append(l)\n",
    "def animate(i):\n",
    "    global num_times\n",
    "    num_times +=1\n",
    "    x = np.linspace(0,1,100)\n",
    "    y = linear_function(alpha,beta,x)\n",
    "    line.set_data(x,y)\n",
    "    for i in range(20): \n",
    "        update_alpha_and_beta()\n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(250):\n",
    "    update_alpha_and_beta()\n",
    "    print(\"alpha:\",alpha,\" beta:\",beta)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(loss))\n",
    "x_axis=np.arange(0,250)\n",
    "plt.plot(x_axis,loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=80,figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((-2,15))\n",
    "plt.scatter(x,y)\n",
    "line, = ax.plot([],[],lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation = animation.FuncAnimation(fig,animate,np.arange(0,250),interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "resulting_animation.save('Nesterov_animation.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Ada Optimization</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy.random import random, randn\n",
    "from matplotlib import pyplot as plt, animation, rcParams, rc\n",
    "\n",
    "\n",
    "def linear_function(alpha,beta,x): return alpha+beta*x\n",
    "rc('animation',html='html5')\n",
    "rcParams['figure.figsize'] = 3, 3\n",
    "\n",
    "beta_true = 6.0\n",
    "alpha_true = 3.0\n",
    "n = 30\n",
    "x = random(n)\n",
    "y = linear_function(alpha_true,beta_true,x)+0.2*randn(n)\n",
    "beta = -1.\n",
    "alpha = 3.\n",
    "learning_rate = 0.04\n",
    "\n",
    "#epsilon\n",
    "epsilon=0.9\n",
    "#r\n",
    "r_alpha = 0\n",
    "r_beta = 0\n",
    "delta = 10**(-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha_and_beta():\n",
    "    global alpha, beta\n",
    "    r_alpha=0\n",
    "    r_beta=0 \n",
    "    y_predicted = linear_function(alpha,beta,x)\n",
    "    #gradient\n",
    "    g_alpha  = 2*(y_predicted-y)\n",
    "    g_beta = x * g_alpha\n",
    "    #accumulate squared gradient\n",
    "    r_alpha = r_alpha + np.multiply(g_alpha.mean(),g_alpha.mean())\n",
    "    r_beta = r_beta + np.multiply(g_beta.mean(),g_beta.mean())\n",
    "    #print(type(r_alpha))\n",
    "    #print(type(g_alpha))\n",
    "    print(g_alpha.mean())\n",
    "    delta_alpha =  -np.multiply(epsilon/(delta+math.sqrt(r_alpha),g_alpha.mean()))\n",
    "    delta_beta = -np.multiply(epsilon/(delta+math.sqrt(r_beta)),g_beta.mean())\n",
    "    #velocity update\n",
    "    alpha = alpha + delta_alpha.mean()\n",
    "    beta = beta + delta_beta.mean()\n",
    "    #print(\"alpha:\",alpha,\" beta:\",beta)\n",
    "def animate(i):\n",
    "    x = np.linspace(0,1,100)\n",
    "    y = linear_function(alpha,beta,x)\n",
    "    line.set_data(x,y)\n",
    "    for i in range(300): \n",
    "        update_alpha_and_beta()\n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "update_alpha_and_beta()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 560x560 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(dpi=80,figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((-2,15))\n",
    "plt.scatter(x,y)\n",
    "line, = ax.plot([],[],lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation = animation.FuncAnimation(fig,animate,np.arange(0,500),interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'float' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mfmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'animation.html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'html5'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html5_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'jshtml'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_jshtml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mto_html5_video\u001b[0;34m(self, embed_limit)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                                 \u001b[0mbitrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'animation.bitrate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m                                 fps=1000. / self._interval)\n\u001b[0;32m-> 1343\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m                 \u001b[0;31m# Now open and base64 encode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m                 \u001b[0mvid64\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodebytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0manim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_anim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                     \u001b[0;31m# Clear the initial frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                     \u001b[0manim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_saved_frame_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_anim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0manim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_anim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36m_init_draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;31m# artists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_frame_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36m_draw_frame\u001b[0;34m(self, framedata)\u001b[0m\n\u001b[1;32m   1760\u001b[0m         \u001b[0;31m# Call the func with framedata and args. If blitting is desired,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0;31m# func needs to return a sequence of any artists that were modified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drawn_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframedata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drawn_artists\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3e523436402e>\u001b[0m in \u001b[0;36manimate\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mupdate_alpha_and_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3e523436402e>\u001b[0m in \u001b[0;36mupdate_alpha_and_beta\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#print(type(r_alpha))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#print(type(g_alpha))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdelta_alpha\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_alpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdelta_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_beta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#velocity update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'float' and 'tuple'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.animation.FuncAnimation at 0x10deb0ba8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulting_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "resulting_animation.save('ada_animation.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Adam</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy.random import random, randn\n",
    "from matplotlib import pyplot as plt, animation, rcParams, rc\n",
    "\n",
    "\n",
    "def linear_function(alpha,beta,x): return alpha+beta*x\n",
    "rc('animation',html='html5')\n",
    "rcParams['figure.figsize'] = 3, 3\n",
    "\n",
    "beta_true = 6.0\n",
    "alpha_true = 3.0\n",
    "n = 30\n",
    "x = random(n)\n",
    "y = linear_function(alpha_true,beta_true,x)+0.2*randn(n)\n",
    "beta = -1.\n",
    "alpha = 3.\n",
    "learning_rate = 0.01\n",
    "\n",
    "#step size\n",
    "epsilon=0.001\n",
    "#p1,p1\n",
    "p1 = 0.9\n",
    "p2 = 0.999\n",
    "delta = 10**(-8)\n",
    "s_alpha=0\n",
    "s_beta=0\n",
    "r_alpha=0\n",
    "r_beta=0\n",
    "num_times=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha_and_beta():\n",
    "    global s_alpha, s_beta,r_alpha,r_beta, alpha,beta\n",
    "    for t in range(10):\n",
    "        for i in range(n):\n",
    "            y_predicted = linear_function(alpha,beta,x[i])\n",
    "            g_alpha  = (2/n)*(y_predicted-y[i])\n",
    "            g_beta = x[i] * g_alpha\n",
    "        #accumulate squared gradient\n",
    "        t+=1\n",
    "        s_alpha = p1*s_alpha + (1-p1)*g_alpha\n",
    "        s_beta = p1*s_beta + (1-p1)*g_beta\n",
    "        r_alpha = p2*r_alpha + (1-p2)*np.multiply(g_alpha,g_alpha)\n",
    "        r_beta = p2*r_beta + (1-p2)*np.multiply(g_beta,g_beta)\n",
    "        s_hat_alpha = s_alpha/(1-p1**t) \n",
    "        s_hat_beta =  s_beta/(1-p1**t)\n",
    "        r_hat_alpha = r_alpha/(1-p2**t)\n",
    "        r_hat_beta = r_beta/(t-p2**t)\n",
    "        delta_alpha = -epsilon*s_hat_alpha/(math.sqrt(r_hat_alpha)+delta) \n",
    "        delta_beta = -epsilon*s_hat_beta/(math.sqrt(r_hat_beta)+delta) \n",
    "        alpha += delta_alpha\n",
    "        beta += delta_beta\n",
    "    \n",
    "def animate(i):\n",
    "    numtimes+=1\n",
    "    x = np.linspace(0,1,100)\n",
    "    y = linear_function(alpha,beta,x)\n",
    "    line.set_data(x,y)\n",
    "    for i in range(20): \n",
    "        update_alpha_and_beta()\n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=80,figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((-2,15))\n",
    "plt.scatter(x,y)\n",
    "line, = ax.plot([],[],lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation = animation.FuncAnimation(fig,animate,np.arange(0,250),interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "resulting_animation.save('adam_animation.mp4', writer=writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
