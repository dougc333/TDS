{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook adapted from Jeremy P. Howard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random, randn\n",
    "from matplotlib import pyplot as plt, animation, rcParams, rc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function(alpha,beta,x): return alpha+beta*x\n",
    "rc('animation',html='html5')\n",
    "rcParams['figure.figsize'] = 3, 3\n",
    "\n",
    "beta_true = 6.0\n",
    "alpha_true = 3.0\n",
    "n = 30\n",
    "x = random(n)\n",
    "y = linear_function(alpha_true,beta_true,x)+0.2*randn(n)\n",
    "beta = -1.\n",
    "alpha = 3.\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Square error is square of difference between predicted and actual data values</p>\n",
    "Define predicted: ${\\hat y} $ and actual:${y}$ \n",
    "<p>Loss is:</p>\n",
    "$({\\hat y}-{y})^2$\n",
    "<p>Previous definition y as linear_function</p>\n",
    "${\\hat y=\\alpha + \\beta x}$\n",
    "<p>To minmize the Loss we take the derivative of the loss wrt alpha and beta, not x. x and y are datapoints\n",
    "which is our dataset we are trying to fit to. The derivative of y is the sum of the partial derivatives of the dependent variables\n",
    "which in this case are alpha and beta. </p>\n",
    "<p></p>\n",
    "$derivative(loss)=\\cfrac{\\partial(loss)}{\\partial \\alpha} + \\cfrac{\\partial(loss)}{\\partial \\beta}$\n",
    "<p></p>\n",
    "$\\cfrac{\\partial(loss)}{\\partial \\alpha}=\\cfrac{(\\hat y - y)^2}{\\partial \\alpha}=\\cfrac{2*(\\hat y-y)*\\partial(\\hat y - y)}{\\partial \\alpha}$\n",
    "<p>Using:</p>\n",
    "$\\cfrac{\\partial \\hat y}{\\partial \\alpha}=1$ \n",
    "<p>and</p>\n",
    "$\\cfrac{\\partial y}{\\partial \\alpha}=0$\n",
    "<p>the derivative of loss wrt alpha for y-hat is:</p>\n",
    "$\\cfrac{\\partial (loss)}{\\partial \\alpha}=2(\\hat y-y)$\n",
    "<p>The derivative of loss WRT beta starts as:</p>  \n",
    "$\\cfrac{\\partial(loss)}{\\partial \\beta}=\\cfrac{(\\hat y - y)^2}{\\partial \\beta}=\\cfrac{2*(\\hat y-y)}{\\partial \\beta}*\\cfrac{\\partial(\\hat y -y)}{\\partial \\beta}$\n",
    "<p></p>\n",
    "$\\cfrac{\\partial \\hat y}{\\partial \\beta}=x$ and\n",
    "$\\cfrac{\\partial y}{\\partial \\beta}=0$\n",
    "<p>the derivative of loss wrt beta for y-hat is:</p>\n",
    "$\\cfrac{\\partial (loss)}{\\partial \\beta}=2x*(\\hat y-y)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha_and_beta():\n",
    "    global alpha, beta\n",
    "    y_predicted = linear_function(alpha,beta,x)\n",
    "    derivative_of_loss_wrt_alpha = 2*(y_predicted-y)\n",
    "    derivative_of_loss_wrt_beta = x* derivative_of_loss_wrt_alpha\n",
    "    alpha = alpha - learning_rate*derivative_of_loss_wrt_alpha.mean()\n",
    "    beta = beta - learning_rate*derivative_of_loss_wrt_beta.mean()\n",
    "def animate(i):\n",
    "    x = np.linspace(0,1,100)\n",
    "    y = linear_function(alpha,beta,x)\n",
    "    line.set_data(x,y)\n",
    "    for i in range(20): \n",
    "        update_alpha_and_beta()\n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=80,figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((-2,15))\n",
    "plt.scatter(x,y)\n",
    "line, = ax.plot([],[],lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation = animation.FuncAnimation(fig,animate,np.arange(0,250),interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out (or delete) the following command, which shows the animation in Jupyter Notebook, \n",
    "# if you want the mp4 saved to disk to be correctly animated. \n",
    "# (Alternatively, you can reset the values of alpha and beta to their initial values \n",
    "# after this command.)\n",
    "\n",
    "resulting_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "resulting_animation.save('linear_animation.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done linear animation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y=\\gamma x^2 + \\beta x + \\alpha$\n",
    "<p></p>\n",
    "$\\cfrac{\\partial(loss)}{\\partial \\gamma}=2x^2(\\hat y-y)$\n",
    "$\\cfrac{\\partial(loss)}{\\partial \\beta}=2x(\\hat y -y)$\n",
    "$\\cfrac{\\partial(loss)}{\\partial \\alpha}=2(\\hat y-y)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Squared Function</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It doesnt make sense to use a quadratic to approximate a linear function,so change the dataset to \n",
    "#be quadratic\n",
    "def square_function(gamma, beta, alpha,x):\n",
    "    return gamma*x**2 + beta*x + alpha\n",
    "\n",
    "beta_true = 2.0\n",
    "alpha_true = 2.0\n",
    "gamma_true = 10.0\n",
    "\n",
    "n = 300\n",
    "x = random(n)\n",
    "y = square_function(gamma_true,beta_true,alpha_true,x)+0.2*randn(n)\n",
    "beta = -1.\n",
    "alpha = 3.\n",
    "gamma = 2.\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_squared():\n",
    "    global gamma, alpha, beta\n",
    "    y_predicted = square_function(gamma,beta,alpha,x)\n",
    "    derivative_of_loss_wrt_gamma = 2*x**2*(y_predicted-y)\n",
    "    derivative_of_loss_wrt_alpha = 2*(y_predicted-y)\n",
    "    derivative_of_loss_wrt_beta = x* derivative_of_loss_wrt_alpha\n",
    "    alpha = alpha - learning_rate*derivative_of_loss_wrt_alpha.mean()\n",
    "    beta = beta - learning_rate*derivative_of_loss_wrt_beta.mean()\n",
    "    gamma = gamma - learning_rate * derivative_of_loss_wrt_gamma.mean()\n",
    "\n",
    "def animate(i):\n",
    "    x = np.linspace(0,1,100)\n",
    "    y = square_function(gamma,beta,alpha,x)\n",
    "    line.set_data(x,y)\n",
    "    for i in range(20): \n",
    "        update_squared()\n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=80,figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((-2,15))\n",
    "plt.scatter(x,y)\n",
    "line, = ax.plot([],[],lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation = animation.FuncAnimation(fig,animate,np.arange(0,250),interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "resulting_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "resulting_animation.save('squared_animation.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done squared animation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>SGD</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random, randn\n",
    "from matplotlib import pyplot as plt, animation, rcParams, rc\n",
    "\n",
    "\n",
    "def linear_function(alpha,beta,x): return alpha+beta*x\n",
    "beta_true = 6.0\n",
    "alpha_true = 3.0\n",
    "n = 30\n",
    "x_data = random(n)\n",
    "y_data = linear_function(alpha_true,beta_true,x_data)+0.2*randn(n)\n",
    "beta = -1.\n",
    "alpha = 3.\n",
    "learning_rate = 0.1\n",
    "num_iters=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89651284 0.68983679 0.86404787 0.5808972  0.10565706 0.82049396\n",
      " 0.65702753 0.07364167 0.38395776 0.41543906 0.77656385 0.94117423\n",
      " 0.13783997 0.11729716 0.21603972 0.06938033 0.73940375 0.08267635\n",
      " 0.82860302 0.1719493  0.34090574 0.14121324 0.02118051 0.62581458\n",
      " 0.79971078 0.15539485 0.62473423 0.16403519 0.80296291 0.37942547]\n",
      "-----\n",
      "[8.01360467 7.05360054 8.38301972 6.51367984 3.80502867 8.08120816\n",
      " 6.8243162  3.68803357 5.2804276  5.42636923 7.78311236 8.36017851\n",
      " 3.73928225 3.65319919 4.25523113 3.41440187 7.58758027 3.32019368\n",
      " 7.94675092 3.76048755 5.1268488  3.75035749 3.23523185 6.7294111\n",
      " 8.0299383  3.70208179 6.68194658 4.05417557 7.60501804 5.45686954]\n"
     ]
    }
   ],
   "source": [
    "print(x_data)\n",
    "print(\"-----\")\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD requires a batch size of 1 \n",
    "def update_alpha_and_beta():\n",
    "    global alpha, beta\n",
    "    for i in range(n):\n",
    "        print(\"i:\",i)\n",
    "        y_predicted_batch = linear_function(alpha,beta,x_data[i])\n",
    "        derivative_of_loss_wrt_alpha = 2*(y_predicted_batch-y_data[i])\n",
    "        derivative_of_loss_wrt_beta = x_data[i]* derivative_of_loss_wrt_alpha\n",
    "        print(\"before iters\",\"alpha:\",alpha,\"beta:\",beta)\n",
    "        for _ in range(num_iters):\n",
    "            #print(\"y_predicted_batch:\",y_predicted_batch)\n",
    "            #print(\"x_batch:\",x_batch,\"y_batch:\",y_batch)\n",
    "            #print(\"learning_rate:\",learning_rate)\n",
    "            #print(\"2*learning_rate*(y_predicted_batch-y_batch)\",2*learning_rate*(y_predicted_batch-y_batch))\n",
    "            #print(\"2*x_batch*(y_predicted_batch-y_batch)\",2*x_batch*(y_predicted_batch-y_batch))\n",
    "            alpha = alpha - 2*learning_rate*(y_predicted_batch-y_data[i])\n",
    "            beta = beta - learning_rate*2*x_data[i]*(y_predicted_batch-y_data[i])\n",
    "            y_predicted_batch = linear_function(alpha,beta,x_data[i])\n",
    "        print(\"after iters\",\"alpha:\",alpha,\"beta:\",beta)\n",
    "def animate():\n",
    "    x = np.linspace(0,1,100)\n",
    "    y = linear_function(alpha,beta,x)\n",
    "    line.set_data(x,y)\n",
    "    #for _ in range(20):\n",
    "    update_alpha_and_beta()\n",
    "    return (line,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 560x560 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(dpi=80,figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((-2,15))\n",
    "plt.scatter(x_data,y_data)\n",
    "line, = ax.plot([],[],lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "before iters alpha: 3.0 beta: -1.0\n",
      "after iters alpha: 5.742815231555843 beta: 0.5304974531877359\n",
      "i: 0\n",
      "before iters alpha: 5.742815231555843 beta: 0.5304974531877359\n",
      "after iters alpha: 5.87377906376032 beta: 0.6035755844969898\n",
      "i: 0\n",
      "before iters alpha: 5.87377906376032 beta: 0.6035755844969898\n",
      "after iters alpha: 5.880032319593362 beta: 0.6070649161940338\n",
      "i: 0\n",
      "before iters alpha: 5.880032319593362 beta: 0.6070649161940338\n",
      "after iters alpha: 5.8803308998032975 beta: 0.6072315246646375\n",
      "i: 0\n",
      "before iters alpha: 5.8803308998032975 beta: 0.6072315246646375\n",
      "after iters alpha: 5.880345156399244 beta: 0.6072394798792422\n",
      "i: 0\n",
      "before iters alpha: 5.880345156399244 beta: 0.6072394798792422\n",
      "after iters alpha: 5.880345837122618 beta: 0.6072398597245118\n",
      "i: 0\n",
      "before iters alpha: 5.880345837122618 beta: 0.6072398597245118\n",
      "after iters alpha: 5.88034586962577 beta: 0.6072398778613491\n",
      "i: 0\n",
      "before iters alpha: 5.88034586962577 beta: 0.6072398778613491\n",
      "after iters alpha: 5.88034587117773 beta: 0.6072398787273461\n",
      "i: 0\n",
      "before iters alpha: 5.88034587117773 beta: 0.6072398787273461\n",
      "after iters alpha: 5.880345871251832 beta: 0.6072398787686958\n",
      "i: 0\n",
      "before iters alpha: 5.880345871251832 beta: 0.6072398787686958\n",
      "after iters alpha: 5.88034587125537 beta: 0.6072398787706702\n",
      "i: 0\n",
      "before iters alpha: 5.88034587125537 beta: 0.6072398787706702\n",
      "after iters alpha: 5.880345871255539 beta: 0.6072398787707647\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255539 beta: 0.6072398787707647\n",
      "after iters alpha: 5.880345871255547 beta: 0.6072398787707691\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.6072398787707691\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "i: 0\n",
      "before iters alpha: 5.880345871255547 beta: 0.60723987877077\n",
      "after iters alpha: 5.880345871255547 beta: 0.60723987877077\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    animate()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_animation = animation.FuncAnimation(fig,animate,np.arange(0,250),interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bug here if it doesnt complete\n",
    "resulting_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "resulting_animation.save('SGD_animation.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>SGD w/momentum</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
