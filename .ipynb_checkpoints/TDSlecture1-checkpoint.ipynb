{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random, randn\n",
    "from matplotlib import pyplot as plt, animation, rcParams, rc\n",
    "def linear_function(alpha, beta, x):\n",
    "    return alpha+beta*x\n",
    "rc('animation',html='html5')\n",
    "rcParams['figure.figsize'] = 3,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Square error is square of difference between predicted and actual data values</p>\n",
    "Define predicted: ${\\hat y} $ and actual:${y}$ \n",
    "<p>Loss is:</p>\n",
    "$({\\hat y}-{y})^2$\n",
    "<p>Previous definition y as linear_function</p>\n",
    "${\\hat y=\\alpha + \\beta x}$\n",
    "<p>To minmize the Loss we take the derivative of the loss wrt alpha and beta. </p>\n",
    "$\\cfrac{\\partial(loss)}{\\partial \\alpha}=\\cfrac{(\\hat y - y)^2}{\\partial \\alpha}=\\cfrac{2*(\\hat y-y)*\\partial(\\hat y - y)}{\\partial \\alpha}$\n",
    "<p>Using:</p>\n",
    "$\\cfrac{\\partial \\hat y}{\\partial \\alpha}=1$ \n",
    "<p>and</p>\n",
    "$\\cfrac{\\partial y}{\\partial \\alpha}=0$\n",
    "<p>the derivative of loss wrt alpha for y-hat is:</p>\n",
    "$\\cfrac{\\partial (loss)}{\\partial \\alpha}=2(\\hat y-y)$\n",
    "<p>The derivative of loss WRT beta starts as:</p>  \n",
    "$\\cfrac{\\partial(loss)}{\\partial \\beta}=\\cfrac{(\\hat y - y)^2}{\\partial \\beta}=\\cfrac{2*(\\hat y-y)}{\\partial \\beta}*\\cfrac{\\partial(\\hat y -y)}{\\partial \\beta}$\n",
    "<p></p>\n",
    "$\\cfrac{\\partial \\hat y}{\\partial \\beta}=x$ and\n",
    "$\\cfrac{\\partial y}{\\partial \\beta}=0$\n",
    "<p>the derivative of loss wrt beta for y-hat is:</p>\n",
    "$\\cfrac{\\partial (loss)}{\\partial \\beta}=2x*(\\hat y-y)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_true = 6.0\n",
    "alpha_true = 3.0\n",
    "n=30\n",
    "x=random(n)\n",
    "y = linear_function(alpha_true,beta_true,x) + 0.2*randn(n)\n",
    "beta=-1.\n",
    "alpha = 3.\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha_and_beta():\n",
    "    global alpha, beta\n",
    "    y_predicted = linear_function(alpha,beta,x)\n",
    "    der_loss_wrt_alpha = 2*(y_predicted-y)\n",
    "    der_loss_wrt_beta = x * der_loss_wrt_alpha\n",
    "    alpha = alpha - learning_rate * der_loss_wrt_alpha.mean()\n",
    "    beta = beta - learning_rate * der_loss_wrt_beta.mean()\n",
    "def animate(i):\n",
    "    x = np.linspace(0,1000)\n",
    "    y = linear_function(alpha,beta,x)\n",
    "    line.set_data(x)\n",
    "    for i in range(20):\n",
    "        update_alpha_and_beta()\n",
    "    return (line,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=80,figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0,1))\n",
    "ax.set_ylim((-2,15))\n",
    "plt.scatter(x,y)\n",
    "line,=ax.plot([],[],lw=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$e^{i\\pi} + 1 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
